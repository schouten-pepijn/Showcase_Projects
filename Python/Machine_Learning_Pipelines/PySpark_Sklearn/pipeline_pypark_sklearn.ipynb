{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline as skPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.02440983 -0.07185289]\n",
      "Intercept: -0.07350052500081823\n",
      "     y_true    y_pred\n",
      "0 -9.615213 -0.154982\n",
      "1  4.593737 -0.136383\n",
      "2  1.952026 -0.170274\n",
      "3 -1.342535 -0.189420\n",
      "4 -4.790354 -0.078791\n",
      "RMSE: 5.687104139114933\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "np.random.seed(87)\n",
    "NUM_SAMPLES = 10000\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# vreate simulated data\n",
    "def data_simulation(num_samples):\n",
    "    X = np.random.rand(num_samples, 2) * 10\n",
    "    y = np.random.rand(num_samples) * 20 - 10\n",
    "    return X, y\n",
    "\n",
    "# split data in train and test\n",
    "def data_splitter(X, y, train_ratio):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=1-train_ratio,\n",
    "                                                    random_state=87)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# create simulated data\n",
    "X_data, y_data = data_simulation(NUM_SAMPLES)\n",
    "\n",
    "# split data in train and test\n",
    "X_train, X_test, y_train, y_test = data_splitter(\n",
    "    X_data,\n",
    "    y_data,\n",
    "    TRAIN_RATIO\n",
    ")\n",
    "\n",
    "# create standardscaler for normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create regressionmodel\n",
    "regression = LinearRegression()\n",
    "\n",
    "# create ML pipeline\n",
    "steps = [\n",
    "    (\"scaler\", scaler),\n",
    "    (\"regression\", regression)\n",
    "]\n",
    "pipeline = skPipeline(steps=steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# evaluate training\n",
    "coefficients = pipeline.named_steps[\"regression\"].coef_\n",
    "intercept = pipeline.named_steps[\"regression\"].intercept_\n",
    "\n",
    "print(f\"Coefficients: {coefficients}\")\n",
    "print(f\"Intercept: {intercept}\")\n",
    "\n",
    "# make and evaluate predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "data = {\"y_true\": y_test, \"y_pred\": y_pred}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline as sparkPipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/21 09:53:07 WARN Instrumentation: [98abb65c] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [0.13348965971885035,0.04080595714807422]\n",
      "Intercept:  -0.35641291108111783\n",
      "+--------------------+-------------------+--------------------+\n",
      "|            features|              label|          prediction|\n",
      "+--------------------+-------------------+--------------------+\n",
      "|[8.42284044860756...|  8.087115265911105| 0.12555900812734877|\n",
      "|[7.46666388690664...|  5.086996075074966|  0.1254555951746139|\n",
      "|[9.34503865374475...| -9.772565396159969|  0.1315229010280709|\n",
      "|[2.25556430373861...|-4.3993419391160105|-0.11777576949341934|\n",
      "|[5.69924586717390...|   6.68215801521853|-0.07701101637688762|\n",
      "+--------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RMSE:  5.844045987881074\n"
     ]
    }
   ],
   "source": [
    "# Create spark sessrion\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Variables\n",
    "NUM_SAMPLES = 10000\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# Create simulated data\n",
    "def data_simulation(num_samples):\n",
    "    simulated_data = (spark.range(num_samples)\n",
    "                    .selectExpr(\n",
    "                        \"id as id\",\n",
    "                        \"(RAND() * 10) as feature1\",\n",
    "                        \"(RAND() * 5) as feature2\",\n",
    "                        \"(RAND() * 20 - 10) as label\"))\n",
    "    return simulated_data\n",
    " \n",
    "\n",
    "# split data in train and test\n",
    "def data_splitter(data, train_ratio):\n",
    "    test_ratio = 1 - train_ratio\n",
    "    train_data, test_data = data.randomSplit(\n",
    "        [train_ratio, test_ratio],\n",
    "        seed=87\n",
    "    )\n",
    "    return train_data, test_data\n",
    "    \n",
    "\n",
    "# create simulated data           \n",
    "simulated_data = data_simulation(NUM_SAMPLES)\n",
    "\n",
    "# create train and test splits\n",
    "training_data, testing_data = data_splitter(\n",
    "    simulated_data,\n",
    "    TRAIN_RATIO\n",
    ")\n",
    "                 \n",
    " \n",
    "# create vector assembler for ML model\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"feature1\", \"feature2\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# create standardscaler for normalization\n",
    "scaler = StandardScaler(inputCol=\"features\",\n",
    "                        outputCol=\"scaledFeatures\"\n",
    ")\n",
    "\n",
    "# create lnear regresion model\n",
    "regression = LinearRegression(\n",
    "    featuresCol=\"scaledFeatures\",\n",
    "    labelCol=\"label\"\n",
    ")\n",
    "\n",
    "# create ML pipeline\n",
    "stages = [\n",
    "    assembler,\n",
    "    scaler,\n",
    "    regression\n",
    "]\n",
    "pipeline = sparkPipeline(stages=stages)\n",
    "pipeline_model = pipeline.fit(training_data)\n",
    "\n",
    "# extract fitting parameters\n",
    "coefficients = pipeline_model.stages[-1].coefficients\n",
    "intercept = pipeline_model.stages[-1].intercept\n",
    "\n",
    "# print fitting parameters\n",
    "print(\"Coefficients: \", coefficients)\n",
    "print(\"Intercept: \", intercept)\n",
    "\n",
    "# create predictions\n",
    "preds = pipeline_model.transform(testing_data)\n",
    "\n",
    "# show the predictions\n",
    "preds.select(\n",
    "    \"features\", \"label\", \"prediction\"\n",
    "    ).show(5)\n",
    "\n",
    "# create evaluation metric\n",
    "evaluator = RegressionEvaluator(\n",
    "    predictionCol=\"prediction\",\n",
    "    labelCol=\"label\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "# evaluate the preditions\n",
    "rmse = evaluator.evaluate(preds)\n",
    "print(\"RMSE: \", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

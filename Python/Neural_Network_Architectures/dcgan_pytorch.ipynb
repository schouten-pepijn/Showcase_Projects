{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "LAT_DIM = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 1\n",
    "LOG_INTERVAL = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator and Discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANGenerator(nn.Module):\n",
    "    def __init__(self, lat_dim, image_size, channels):\n",
    "        super(GANGenerator, self).__init__()\n",
    "        self.input_size = image_size // 4\n",
    "        \n",
    "        self.lin = nn.Linear(lat_dim, 128 * self.input_size ** 2)\n",
    "        self.bn1 = nn.BatchNorm2d(128, 0.8)\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.cn1 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(128, 0.8)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.cn2 = nn.Conv2d(128, 64, 3, stride=1, padding=1)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm2d(64, 0.8)\n",
    "        self.cn3 = nn.Conv2d(64, channels, 3, stride=1, padding=1)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = x.view(x.shape[0], 128, self.input_size, self.input_size)\n",
    "        x = self.bn1(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.cn1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x, inplace=True)\n",
    "        x = self.up2(x)\n",
    "        x = self.cn2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.leaky_relu(x, inplace=True)\n",
    "        x = self.cn3(x)\n",
    "        out = self.act(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDiscriminator(nn.Module):\n",
    "    def __init__(self, image_size, channels):\n",
    "        super(GANDiscriminator, self).__init__()\n",
    "        \n",
    "        self.disc_model = nn.Sequential(\n",
    "            nn.Conv2d(channels, 16, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "        )\n",
    "        \n",
    "        \n",
    "        ds_size = image_size // 2 ** 4\n",
    "        self.adverse_lyr = nn.Linear(128 * ds_size ** 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.disc_model(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        out = torch.sigmoid(self.adverse_lyr(x))\n",
    "        return out  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the discriminator and generator models\n",
    "gen = GANGenerator(LAT_DIM, IMAGE_SIZE, CHANNELS)\n",
    "disc = GANDiscriminator(IMAGE_SIZE, CHANNELS)\n",
    "\n",
    "gen = torch.compile(gen)\n",
    "disc = torch.compile(disc)\n",
    "\n",
    "# define the loss metric\n",
    "def gen_loss_func(pred_probs, good_img):\n",
    "    return F.binary_cross_entropy(pred_probs, good_img)\n",
    "\n",
    "def disc_loss_func(real_probs, fake_probs, good_img, bad_img):\n",
    "    real_loss = F.binary_cross_entropy(real_probs, good_img)\n",
    "    fake_loss = F.binary_cross_entropy(fake_probs, bad_img)\n",
    "    return (real_loss + fake_loss) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset and corresponding dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"./data/mnist/\",\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), \n",
    "             transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# define the optimization schedule for both G and D\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=LR)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number   0 | batch number    0 | generator loss = 0.682919 | discriminator loss = 0.692570\n",
      "epoch number   0 | batch number  100 | generator loss = 1.353329 | discriminator loss = 0.392550\n",
      "epoch number   0 | batch number  200 | generator loss = 1.608291 | discriminator loss = 0.389186\n",
      "epoch number   0 | batch number  300 | generator loss = 1.080813 | discriminator loss = 0.581661\n",
      "epoch number   0 | batch number  400 | generator loss = 0.915626 | discriminator loss = 0.338195\n",
      "epoch number   0 | batch number  500 | generator loss = 1.142022 | discriminator loss = 0.273801\n",
      "epoch number   0 | batch number  600 | generator loss = 0.633800 | discriminator loss = 0.784687\n",
      "epoch number   0 | batch number  700 | generator loss = 2.952504 | discriminator loss = 0.064790\n",
      "epoch number   0 | batch number  800 | generator loss = 1.005011 | discriminator loss = 0.796017\n",
      "epoch number   0 | batch number  900 | generator loss = 0.354879 | discriminator loss = 1.133571\n",
      "epoch number   0 | batch number 1000 | generator loss = 0.463851 | discriminator loss = 0.638719\n",
      "epoch number   0 | batch number 1100 | generator loss = 1.674038 | discriminator loss = 0.486520\n",
      "epoch number   0 | batch number 1200 | generator loss = 1.152708 | discriminator loss = 0.461113\n",
      "epoch number   0 | batch number 1300 | generator loss = 0.550274 | discriminator loss = 1.138933\n",
      "epoch number   0 | batch number 1400 | generator loss = 0.715678 | discriminator loss = 0.737947\n",
      "epoch number   0 | batch number 1500 | generator loss = 0.685883 | discriminator loss = 0.463868\n",
      "epoch number   0 | batch number 1600 | generator loss = 0.260813 | discriminator loss = 0.906906\n",
      "epoch number   0 | batch number 1700 | generator loss = 2.565623 | discriminator loss = 0.371578\n",
      "epoch number   0 | batch number 1800 | generator loss = 2.422087 | discriminator loss = 0.241417\n",
      "epoch number   1 | batch number   25 | generator loss = 3.276070 | discriminator loss = 0.138229\n",
      "epoch number   1 | batch number  125 | generator loss = 2.008201 | discriminator loss = 0.316570\n",
      "epoch number   1 | batch number  225 | generator loss = 3.960031 | discriminator loss = 0.667621\n",
      "epoch number   1 | batch number  325 | generator loss = 1.319662 | discriminator loss = 0.153700\n",
      "epoch number   1 | batch number  425 | generator loss = 2.013492 | discriminator loss = 0.242516\n",
      "epoch number   1 | batch number  525 | generator loss = 6.217556 | discriminator loss = 0.065503\n",
      "epoch number   1 | batch number  625 | generator loss = 5.082089 | discriminator loss = 0.245247\n",
      "epoch number   1 | batch number  725 | generator loss = 2.937323 | discriminator loss = 0.217839\n",
      "epoch number   1 | batch number  825 | generator loss = 2.002285 | discriminator loss = 0.150580\n",
      "epoch number   1 | batch number  925 | generator loss = 5.496859 | discriminator loss = 0.390274\n",
      "epoch number   1 | batch number 1025 | generator loss = 3.522953 | discriminator loss = 0.128585\n",
      "epoch number   1 | batch number 1125 | generator loss = 2.974981 | discriminator loss = 0.078990\n",
      "epoch number   1 | batch number 1225 | generator loss = 2.139632 | discriminator loss = 0.543482\n",
      "epoch number   1 | batch number 1325 | generator loss = 2.703933 | discriminator loss = 0.060230\n",
      "epoch number   1 | batch number 1425 | generator loss = 3.147380 | discriminator loss = 0.135593\n",
      "epoch number   1 | batch number 1525 | generator loss = 2.320699 | discriminator loss = 0.175484\n",
      "epoch number   1 | batch number 1625 | generator loss = 5.265565 | discriminator loss = 0.181934\n",
      "epoch number   1 | batch number 1725 | generator loss = 2.421401 | discriminator loss = 0.212911\n",
      "epoch number   1 | batch number 1825 | generator loss = 2.963084 | discriminator loss = 0.114142\n",
      "epoch number   2 | batch number   50 | generator loss = 2.835084 | discriminator loss = 0.247917\n",
      "epoch number   2 | batch number  150 | generator loss = 3.099869 | discriminator loss = 0.468085\n",
      "epoch number   2 | batch number  250 | generator loss = 1.903360 | discriminator loss = 0.306390\n",
      "epoch number   2 | batch number  350 | generator loss = 2.222046 | discriminator loss = 0.278965\n",
      "epoch number   2 | batch number  450 | generator loss = 2.432616 | discriminator loss = 0.165653\n",
      "epoch number   2 | batch number  550 | generator loss = 3.350063 | discriminator loss = 0.199665\n",
      "epoch number   2 | batch number  650 | generator loss = 3.629832 | discriminator loss = 0.075034\n",
      "epoch number   2 | batch number  750 | generator loss = 4.361871 | discriminator loss = 0.336476\n",
      "epoch number   2 | batch number  850 | generator loss = 1.277526 | discriminator loss = 0.262342\n",
      "epoch number   2 | batch number  950 | generator loss = 3.292579 | discriminator loss = 0.076425\n",
      "epoch number   2 | batch number 1050 | generator loss = 1.370212 | discriminator loss = 0.578454\n",
      "epoch number   2 | batch number 1150 | generator loss = 3.216657 | discriminator loss = 0.015949\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"./images_mnist\", exist_ok=True)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for idx, (images, _) in enumerate(dataloader):\n",
    "\n",
    "        # get a batch of real images\n",
    "        good_img = torch.ones(images.shape[0], 1)\n",
    "        bad_img = torch.zeros(images.shape[0], 1)\n",
    "\n",
    "        # get a real image\n",
    "        actual_images = images.type(torch.FloatTensor)\n",
    "\n",
    "        # train the generator model\n",
    "        opt_gen.zero_grad()\n",
    "\n",
    "        # generate a batch of images based on random noise as input\n",
    "        noise = torch.randn(images.shape[0], LAT_DIM)\n",
    "        gen_images = gen(noise)\n",
    "\n",
    "        # generator model optimization - how well can it fool the discriminator\n",
    "        generator_loss = gen_loss_func(\n",
    "            disc(gen_images),\n",
    "            good_img\n",
    "        )\n",
    "        generator_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # train the discriminator model\n",
    "        opt_disc.zero_grad()\n",
    "\n",
    "        # calculate discriminator loss as average of mistakes(losses) in confusing real images as fake and vice versa\n",
    "        discriminator_loss = disc_loss_func(\n",
    "            disc(actual_images),\n",
    "            disc(gen_images.detach()),\n",
    "            good_img,\n",
    "            bad_img\n",
    "        )\n",
    "\n",
    "        # discriminator model optimization\n",
    "        discriminator_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        batches_completed = epoch * len(dataloader) + idx\n",
    "        if batches_completed % LOG_INTERVAL == 0:\n",
    "            print(f\"epoch number {epoch:3}\"\n",
    "                  f\" | batch number {idx:4}\"\n",
    "                  f\" | generator loss = {generator_loss.item():.6f}\"\n",
    "                  f\" | discriminator loss = {discriminator_loss.item():.6f}\"\n",
    "            )\n",
    "            save_image(gen_images.data[:25],\n",
    "                       f\"images_mnist/{epoch}_{batches_completed}.png\",\n",
    "                       nrow=5,\n",
    "                       normalize=True\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
